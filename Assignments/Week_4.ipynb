{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Assignment: Week 4**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **1. Business Understanding**\n",
    "The goal of this assignment is to understand the use of pretrained word embeddings and gain a deeper understanding of word representations. Specifically, the objective is to analyze word vectors using GloVe embeddings, compute a vector operation that combines semantic properties of words, and interpret the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Data Understanding**\n",
    "### Dataset:\n",
    "**GloVe (Global Vectors for Word Representation)**: `glove.6B.100d.txt`, a file containing pretrained word vectors of 100 dimensions.\n",
    "\n",
    "GloVe is a pretrained word embedding model based on statistical properties of large corpora. It represents words as vectors in a way that preserves semantic and syntactic relationships.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Data Preparation**\n",
    "\n",
    "### Code to Load and Prepare the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: man\n",
      "Found: woman\n",
      "Found: king\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to load GloVe embeddings\n",
    "def load_glove_model(file_path):\n",
    "    embeddings = {}\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.array(values[1:], dtype='float32')\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "# Path to the GloVe file\n",
    "glove_path = \"glove.6B.100d.txt\"\n",
    "glove_embeddings = load_glove_model(glove_path)\n",
    "\n",
    "# Check if target words are in the vocabulary\n",
    "words_to_check = [\"man\", \"woman\", \"king\"]\n",
    "for word in words_to_check:\n",
    "    if word in glove_embeddings:\n",
    "        print(f\"Found: {word}\")\n",
    "    else:\n",
    "        print(f\"Not found: {word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling\n",
    "Explanation:\n",
    "The vector operation vec(\"woman\") - vec(\"man\") + vec(\"king\") combines semantic relationships. The nearest words to the resulting vector will be found using cosine similarity as the distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest words to the resulting vector:\n",
      "king: 0.1448\n",
      "queen: 0.2166\n",
      "monarch: 0.3066\n",
      "throne: 0.3167\n",
      "daughter: 0.3191\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Compute the resulting vector\n",
    "vec_woman = glove_embeddings[\"woman\"]\n",
    "vec_man = glove_embeddings[\"man\"]\n",
    "vec_king = glove_embeddings[\"king\"]\n",
    "\n",
    "result_vector = vec_woman - vec_man + vec_king\n",
    "\n",
    "# Function to find the closest vectors using cosine similarity\n",
    "def find_closest_vectors(embeddings, target_vector, top_n=5):\n",
    "    distances = {}\n",
    "    for word, vector in embeddings.items():\n",
    "        distances[word] = cosine(target_vector, vector)\n",
    "    closest = sorted(distances.items(), key=lambda x: x[1])[:top_n]\n",
    "    return closest\n",
    "\n",
    "# Find the nearest words\n",
    "nearest_words = find_closest_vectors(glove_embeddings, result_vector)\n",
    "\n",
    "print(\"Closest words to the resulting vector:\")\n",
    "for word, score in nearest_words:\n",
    "    print(f\"{word}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "Analysis of Results:\n",
    "What is the closest word?\n",
    "The word closest to the computed vector likely represents the semantic concept of \"a female ruler,\" given the inputs of woman, man, and king.\n",
    "\n",
    "Interpretation of the Vector Operation:\n",
    "The operation vec(\"woman\") - vec(\"man\") + vec(\"king\") translates the gendered concept of king into its female equivalent, while preserving the notion of royalty. This demonstrates how GloVe embeddings capture semantic and syntactic relationships between words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
